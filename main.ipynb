{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1imySp36b3hTs28zJzof7Qta8Z6nZmBbD",
      "authorship_tag": "ABX9TyN08ALf+a/Qjszv16Afoukv",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AndyMDH/pneumonia_detection_cnn/blob/main/main.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# CSCK506  End of Module: Pneumonia Detection through Convolutional Neural Network (CNN)\n",
        "\n"
      ],
      "metadata": {
        "id": "sKYV16KhiNal"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Table of Contents\n",
        "1. [Introduction](#section-1-introduction)\n",
        "2. [Data Exploration & Analysis](#section-2-data-exploration--analysis)\n",
        "3. [Data Preparation](#section-3-data-preparation)\n",
        "4. [Create Vocabulary](#section-4-create-vocabulary)\n",
        "5. [Feature Extraction](#section-5-feature-extraction)\n",
        "6. [Seq2Seq Model Development](#section-6-seq2seq-model-development)\n",
        "7. [Model Evaluation](#section-7-model-evaluation)\n",
        "8. [Chatbot Implementation and Manual Testing](#section-8-chatbot-implementation-and-manual-testing)"
      ],
      "metadata": {
        "id": "dpfCeVsEiwvH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "## Introduction\n",
        "\n",
        "Pneumonia poses a severe threat to human health, being a potentially life-threatening infectious illness that typically affects one or both lungs. It is frequently triggered by bacteria, notably Streptococcus pneumoniae. According to the World Health Organization (WHO), pneumonia is responsible for one in three deaths in India (Varshni et al., 2019). Medical practitioners often rely on X-ray scans to diagnose pneumonia, distinguishing between bacterial and viral types.\n",
        "\n",
        "This Jupyter notebook delves into the realm of automated pneumonia detection using Convolutional Neural Networks (CNNs). Specifically, it addresses the task of training a CNN model to differentiate between healthy lung scans and those afflicted with pneumonia. The dataset utilised for this endeavor is sourced from the Kaggle competition repository, offering a collection of chest X-ray images categorised as pneumonia-positive and normal.\n",
        "\n",
        "\n",
        "**This task involves, but is not limited to:**\n",
        "\n",
        "a. CNN Model Development:\n",
        "\n",
        "- Write code to train a CNN model using the provided dataset.\n",
        "- Objective: Achieve optimal performance in distinguishing between healthy and pneumonia-infected lung images.\n",
        "\n",
        "    - **Key considerations:**\n",
        "      - Define CNN architecture, including convolution-pooling blocks.\n",
        "      - Fine-tune parameters like strides, padding, and activation functions for accuracy.\n",
        "      - Implement strategies to prevent overfitting and ensure model generalization.\n",
        "\n",
        "b. Training and Evaluation:\n",
        "\n",
        "- Train the CNN model using the provided training dataset.\n",
        "Fine-tune hyperparameters using validation data to enhance performance.\n",
        "- Evaluate the model's accuracy using a separate test dataset to validate pneumonia detection in chest X-ray images.\n",
        "\n",
        "This Jupyter Notebook was collaboratively prepared by:\n",
        "\n",
        "- Minh-Dat Andy Ho Huu\n",
        "- Santiago Fernandez Blanco\n",
        "- Ismael Saumtally\n",
        "- Chi Chuen Wan\n",
        "- Chui Yi Wong"
      ],
      "metadata": {
        "id": "Fp0cMtR7i1cn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Import Dependencies"
      ],
      "metadata": {
        "id": "_znUfAOJvTQN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Standard library imports\n",
        "import itertools\n",
        "import logging\n",
        "import os\n",
        "import re\n",
        "import unicodedata\n",
        "import urllib.request\n",
        "from collections import defaultdict\n",
        "from typing import List, Optional, Set, Tuple\n",
        "from zipfile import ZipFile\n",
        "\n",
        "# Related third party imports\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Activation, Conv2D, MaxPooling2D, Flatten, Dropout, BatchNormalization\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from sklearn.metrics import precision_recall_curve, roc_curve, accuracy_score, confusion_matrix, precision_score, recall_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Warnings configuration\n",
        "import warnings"
      ],
      "metadata": {
        "id": "5o3vHSwgsqpM"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "warnings.filterwarnings(action='ignore',category=DeprecationWarning)\n",
        "warnings.filterwarnings(action='ignore',category=FutureWarning)"
      ],
      "metadata": {
        "id": "Xtp6hDmr4-8Q"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Download Pneumonia Dataset\n",
        "\n",
        "The Corpus can be downloaded here: [Chest X-Ray Images (Pneumonia)](https://www.kaggle.com/datasets/paultimothymooney/chest-xray-pneumonia?resource=download)"
      ],
      "metadata": {
        "id": "V4bmI1Aq5IGw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "logging.basicConfig(level=logging.INFO)\n",
        "logger = logging.getLogger(__name__)"
      ],
      "metadata": {
        "id": "h_sLk2I26QO7"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Load Dataset into DataFrame"
      ],
      "metadata": {
        "id": "6AhITM_N9sJV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Mount Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Define your dataset directory and file path\n",
        "DATASET_DIR = '/content/drive/My Drive/path/to/dataset'\n",
        "DATASET_FILE = DATASET_DIR + '/your_dataset_file.ext'\n",
        "\n",
        "# Check if the dataset file exists\n",
        "if os.path.exists(DATASET_FILE):\n",
        "    print(f'{DATASET_FILE} already exists')\n",
        "else:\n",
        "    print(f'The dataset file is not found at {DATASET_FILE}. Please make sure it is in the correct location.')\n"
      ],
      "metadata": {
        "id": "w-pQ_8vFTRCN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Alternatively, you can run the code block below to download and extract the chest x-ray files automatically.\n",
        "\n",
        "def download_file(url, destination):\n",
        "    try:\n",
        "        urllib.request.urlretrieve(url, destination)\n",
        "        logger.info(f'Downloaded file from {url} to {destination}')\n",
        "    except Exception as e:\n",
        "        logger.error(f'Error downloading file: {e}')\n",
        "\n",
        "def extract_zip(zip_path, extract_path):\n",
        "    try:\n",
        "        with ZipFile(zip_path, 'r') as zip_ref:\n",
        "            zip_ref.extractall(extract_path)\n",
        "        logger.info(f'Extracted {zip_path} to {extract_path}')\n",
        "    except Exception as e:\n",
        "        logger.error(f'Error extracting zip file: {e}')\n",
        "\n",
        "def create_directory(directory):\n",
        "    if not os.path.exists(directory):\n",
        "        os.makedirs(directory)\n",
        "        logger.info(f'Created directory: {directory}')\n",
        "\n",
        "DATASET_NAME = 'chest_x_ray'\n",
        "DATASET_URL = 'https://www.kaggle.com/datasets/paultimothymooney/chest-xray-pneumonia?resource=download'\n",
        "DATASET_DIR = os.path.join(DATASET_NAME)\n",
        "DATASET_ZIP = os.path.join(DATASET_DIR, 'archive.zip')\n",
        "\n",
        "# Check if dataset directory already exists\n",
        "if os.path.exists(DATASET_DIR):\n",
        "    print(f'{DATASET_NAME} already exists')\n",
        "else:\n",
        "    if os.path.exists(DATASET_ZIP):\n",
        "        create_directory(DATASET_DIR)\n",
        "        extract_zip(DATASET_ZIP, CORPUS_DIR)\n",
        "        os.remove(DATASET_ZIP)\n",
        "        print(f'{DATASET_URL_NAME} extracted')\n",
        "    else:\n",
        "        print(f'To obtain the \"{DATASET_NAME}\" dataset, please follow these steps:')\n",
        "        print(f'1. Manually download the WikiQA dataset from: {DATASET_URL}')\n",
        "        print(f'2. Place the downloaded \"archive.zip\" file in the \"{DATASET_DIR}\" folder.')\n",
        "        print(f'3. Rerun this script after placing the corpus in the correct location.')\n"
      ],
      "metadata": {
        "id": "JO9DTt_9TXxH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define directories\n",
        "train_dir = 'data/train'\n",
        "validation_dir = 'data/validation'\n",
        "test_dir = 'data/test'"
      ],
      "metadata": {
        "id": "MbmTQiTC96u1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Exploratory Data Analysis"
      ],
      "metadata": {
        "id": "iY2sVdjG-PLT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Check dataset dimensions\n",
        "print(\"Training images shape:\", train_images.shape)\n",
        "print(\"Training labels shape:\", train_labels.shape)\n",
        "print(\"Test images shape:\", test_images.shape)\n",
        "print(\"Test labels shape:\", test_labels.shape)"
      ],
      "metadata": {
        "id": "I6xUtcbbI06t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualise sample images\n",
        "plt.figure(figsize=(10, 10))\n",
        "for i in range(25):\n",
        "    plt.subplot(5, 5, i + 1)\n",
        "    plt.xticks([])\n",
        "    plt.yticks([])\n",
        "    plt.grid(False)\n",
        "    plt.imshow(train_images[i], cmap=plt.cm.binary)\n",
        "    plt.xlabel(class_names[train_labels[i]])\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "3hLojhHDI5tK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "## Data Preprocessing\n"
      ],
      "metadata": {
        "id": "1rrwYa1MJCKB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def create_augmented_data_generator(train_images, train_labels):\n",
        "    # Call the ImageDataGenerator class for training data augmentation\n",
        "    train_datagen = ImageDataGenerator(\n",
        "        rotation_range=20,\n",
        "        width_shift_range=0.1,\n",
        "        height_shift_range=0.1,\n",
        "        horizontal_flip=True,\n",
        "        fill_mode='nearest',\n",
        "        rescale=1./255.  # Rescale training data\n",
        "    )\n",
        "\n",
        "    # Pass in arguments to the flow method for training data\n",
        "    train_data_generator = train_datagen.flow(\n",
        "        x=train_images.reshape(-1, 28, 28, 1),  # Reshape images to fit NN input shape\n",
        "        y=train_labels,\n",
        "        batch_size=32\n",
        "    )\n",
        "\n",
        "    return train_data_generator\n",
        "\n",
        "def create_test_data_generator(test_images, test_labels):\n",
        "    # Call the ImageDataGenerator class to rescale images for test data (without augmentation)\n",
        "    test_datagen = ImageDataGenerator(rescale=1./255.)\n",
        "\n",
        "    # Pass in arguments to the flow method for test data\n",
        "    test_data_generator = test_datagen.flow(\n",
        "        x=test_images.reshape(-1, 28, 28, 1),  # Reshape images to fit NN input shape\n",
        "        y=test_labels,\n",
        "        batch_size=32\n",
        "    )\n",
        "\n",
        "    return test_data_generator"
      ],
      "metadata": {
        "id": "FiGCGKpAN67G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "### References:\n",
        "\n",
        "Varshni, D., Thakral, K., Agarwal, L., Nijhawan, R. and Mittal, A. (2019). Pneumonia Detection Using CNN based Feature Extraction. [online] IEEE Xplore. doi:https://doi.org/10.1109/ICECCT.2019.8869364."
      ],
      "metadata": {
        "id": "gaHb3cx9texv"
      }
    }
  ]
}